{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that you have pytorch installed, instructions are here: https://pytorch.org/get-started/locally/ , prefferably do it with anaconda if you can, I think that will lead to less problems down the road if we use other libraries.\n",
    "\n",
    "If cuda toolkit isnt available and you have an nvidia gpu try to get that too (it might be contained within anaconda pytorch package): https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html\n",
    "\n",
    "Also note that because the dataset is large I added it to the .gitignore, you should download it from here : https://www.kaggle.com/c/cassava-leaf-disease-classification/data, and extract it into the data/ folder of the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import skorch\n",
    "\n",
    "from torch import FloatTensor, LongTensor, nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets, models\n",
    "from IPython.core.debugger import set_trace\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = True\n",
    "if not torch.cuda.is_available() or not use_cuda:\n",
    "    print(\"if you have an nvidia gpu get the cuda core package\")\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print(\"cuda is available\")\n",
    "    # torch.cuda.set_device(0) # possible fix to illegal memory access error\n",
    "    device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into train and test sets and loading the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setting the path to the directory containing the pics\n",
    "path = './data/train_images'\n",
    "test_path = './data/test_images'\n",
    "\n",
    "labelled_dataset = pd.read_csv(r'./data/train.csv')\n",
    "submission = pd.read_csv(r'./data/sample_submission.csv')\n",
    "\n",
    "with open('./data/label_num_to_disease_map.json') as f:\n",
    "    mapping_dict = json.load(f)\n",
    "print(mapping_dict)\n",
    "\n",
    "#labelled_dataset = labelled_dataset.head(250) # tiny dataset for fast debugging, comment when training for real\n",
    "\n",
    "# Parameters\n",
    "train, test = train_test_split(labelled_dataset, test_size=0.25, random_state=7, stratify=labelled_dataset.label)\n",
    "\n",
    "should_match_index = 6\n",
    "print(labelled_dataset.values[should_match_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(labelled_dataset.label) # counts the elements' frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Cassava Bacterial Blight (CBB) appears 1087 times<br>\n",
    "Label Cassava Brown Streak Disease (CBSD) appears 2189 times<br>\n",
    "Label Cassava Green Mottle (CGM) appears 2386 times<br>\n",
    "Label Cassava Mosaic Disease (CMD) appears 13158 times<br>\n",
    "Label Healthy appears 2577 times<br>\n",
    "Because the labels arent equally represented the dataset split is stratified so each split has an equal amount of a certain label\n",
    "<br><br>\n",
    "Create custom dataset class for the images, and a transform to be applied to these images as part of preprocessing for learning <br>\n",
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, data, path , transform = None):\n",
    "        super().__init__()\n",
    "        self.data = data.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_name,label = self.data[index]\n",
    "        img_path = os.path.join(self.path, img_name)\n",
    "        image = img.imread(img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# original resolution is 800 x 600\n",
    "# Parameters\n",
    "cassava_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((600,600)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(299), #minimum is 299 for inceptionv3 224 for everything else\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    # (the means and standard deviations of each of the 3 image channels)\n",
    "])\n",
    "\n",
    "train_dataset = CassavaDataset(train, path, cassava_transform )\n",
    "test_dataset = CassavaDataset(test, path, cassava_transform)\n",
    "valid_dataset = CassavaDataset(submission, test_path, cassava_transform)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(labelled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0] # how a transformed image tensor looks like, its label is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_epochs = 15 # on final training this should be high (around 30 for my desktop pc)\n",
    "num_classes = 5 # 5 labels\n",
    "batch_size = 28 # minimum batch size for inception v3 is 2, good general range seems to be 20 to 32\n",
    "learning_rate = 0.0003\n",
    "early_stopping_threshold = 3 # this many epochs of no improvement stops trainining\n",
    "\n",
    "# using Adam optimizer, the max batch size for me is around 28, after that it uses too much vram (i have 8gb)\n",
    "# using SGD optimizer, i can use up to 32\n",
    "# using different pre processing params, i could get bigger batch sizes since the images would be smaller\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True, num_workers=0,pin_memory=True,drop_last=True)\n",
    "valid_dataloader = DataLoader(dataset = valid_dataset, batch_size = batch_size, shuffle=False, num_workers=0,pin_memory=True,drop_last=True)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False, num_workers=0,pin_memory=True,drop_last=True)\n",
    "# pin memory should be enabled if you use cuda cores to speed up transfer between cpu and gpu,\n",
    "# drop last is there if the last batch contains 1 sample for inception v3 (if its not enabled for inception theres an error)\n",
    "# num workers is 0 unless you're using linux or mac os x, because paralelization in windows is broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(index):  \n",
    "    plt.imshow(img.imread('{}/{}'.format(path,labelled_dataset.values[index][0]))) # set the correct resolution here\n",
    "    print('Index: {}'.format(labelled_dataset.values[index][1]))\n",
    "    print('Filename: {}'.format(labelled_dataset.values[index][0]))\n",
    "    \n",
    "show_image(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using resnet 18 pretrained pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__) \n",
    "# Use this number below as the torchvision version for the alternative resnet model or else theres a version conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection below, choices are \"resnet\", \"alexnet\", \"vgg\", \"google_net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_string):\n",
    "    if model_string == \"google_net\":\n",
    "        net = models.inception_v3(pretrained=True,aux_logits=False) # googlenet is based on inception v1, this is improved\n",
    "        net = net.cuda() if use_cuda else net\n",
    "        num_ftrs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    if model_string == \"vgg\":\n",
    "        net = models.vgg16(pretrained=True)\n",
    "        net = net.cuda() if use_cuda else net\n",
    "        net.fc = nn.Linear(4096, num_classes)\n",
    "\n",
    "    if model_string == \"alexnet\":\n",
    "        net = models.alexnet(pretrained=True)\n",
    "        net = net.cuda() if use_cuda else net  \n",
    "        net.fc = nn.Linear(4096, num_classes)\n",
    "\n",
    "    if model_string == \"resnet\":\n",
    "        #net = torch.hub.load('pytorch/vision:v0.2.2', 'resnet18', pretrained=True) \n",
    "        net = models.resnet18(pretrained=True)\n",
    "        net = net.cuda() if use_cuda else net\n",
    "        num_ftrs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "    net.fc = net.fc.cuda() if use_cuda else net.fc    \n",
    "    return net\n",
    "    \n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do evaluation, (still have to try out parameters specified in paper, find out which are useful) <br>The original base code for the block above this text and 2 blocks below was found at the following link, but it was modified for our dataset and to work with our 4 different models not just resnet: https://www.pluralsight.com/guides/introduction-to-resnet <br> <br> What I did with the models is called feature extraction, the models were all pretrained on imagenet: <br>\n",
    "\n",
    "In feature extraction, we start with a pretrained model and only update the final layer weights from which we derive predictions. It is called feature extraction because we use the pretrained CNN as a fixed feature-extractor, and only change the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will plot the accuracy of the models below and save them to a file\n",
    "def plot_model_acc():\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.title(\"Train-Validation Accuracy for {}\".format(model_name))\n",
    "    plt.plot(train_acc, label='train')\n",
    "    plt.plot(val_acc, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('accuracy', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('./plots/{}_e{}_lr{}_bs{}.png'.format(model_name,n_epochs,str(learning_rate).replace(\".\",\"dot\"),batch_size), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This runs all the models, cross validation for all of them is below, this can be used for training and CV for finding optimal parameters\n",
    "# Parameters\n",
    "skip_this = True\n",
    "model_index = 0 # set model index to use here\n",
    "string_array = [\"google_net\",\"alexnet\",\"vgg\",\"resnet\"]\n",
    "\n",
    "first_run = True\n",
    "while(True and not skip_this):\n",
    "    if(len(string_array) > 0):\n",
    "        if not first_run:\n",
    "            #Print and save graph\n",
    "            plot_model_acc()\n",
    "\n",
    "            del criterion # free up vram\n",
    "            del optimizer\n",
    "            del net\n",
    "            torch.cuda.empty_cache()\n",
    "            model_name = string_array.pop(0)\n",
    "            net = get_model(model_name)\n",
    "        else:\n",
    "            model_name = string_array[model_index]\n",
    "            net = get_model(model_name)\n",
    "            string_array.remove(model_name)\n",
    "            first_run = False\n",
    "\n",
    "        # Parameters\n",
    "        criterion = nn.CrossEntropyLoss() # used this since we have 5 mutually exclusive classes\n",
    "        #either one of the optimizers work\n",
    "        #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        improvement_patience = 0\n",
    "    else:\n",
    "        plot_model_acc()\n",
    "        break\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Using model: {}\".format(model_name))\n",
    "    print_every = int(len(train_dataloader)*0.1) # print upon completion of every 10% of the dataset\n",
    "    if print_every == 0: print_every = 1\n",
    "    valid_loss_min = np.Inf\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    total_step = len(train_dataloader)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total=0\n",
    "        print(f'Epoch {epoch}\\n')\n",
    "        for batch_idx, (data_, target_) in enumerate(train_dataloader):\n",
    "            data_, target_ = data_.to(device), target_.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(data_)\n",
    "            #if model_name == \"google_net\": # for inception v3 (the google model we use): \n",
    "                # net(data_) returns logits and aux logits in a touple, we just use logits\n",
    "                #outputs = outputs[0]\n",
    "            loss = criterion(outputs, target_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _,pred = torch.max(outputs, dim=1)\n",
    "\n",
    "            #set_trace() # Debugger entrypoint for inspecting predictions\n",
    "\n",
    "            correct += torch.sum(pred==target_).item()\n",
    "            total += target_.size(0)\n",
    "            if (batch_idx) % print_every == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "        train_acc.append(100 * correct / total)\n",
    "        train_loss.append(running_loss/total_step)\n",
    "        print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "        batch_loss = 0\n",
    "        total_t=0\n",
    "        correct_t=0\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for data_t, target_t in (test_dataloader):\n",
    "                data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "                outputs_t = net(data_t)\n",
    "                loss_t = criterion(outputs_t, target_t)\n",
    "                batch_loss += loss_t.item()\n",
    "                _,pred_t = torch.max(outputs_t, dim=1)\n",
    "                correct_t += torch.sum(pred_t==target_t).item()\n",
    "                total_t += target_t.size(0)\n",
    "            val_acc.append(100 * correct_t/total_t)\n",
    "            val_loss.append(batch_loss/len(test_dataloader))\n",
    "            network_learned = batch_loss < valid_loss_min\n",
    "            print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "\n",
    "            if network_learned:\n",
    "                valid_loss_min = batch_loss\n",
    "                torch.save(net.state_dict(), './data/{}_best_model.pt'.format(model_name))\n",
    "                print('Improvement-Detected, save-model')\n",
    "            else:\n",
    "                improvement_patience += 1\n",
    "        if improvement_patience > early_stopping_threshold: break\n",
    "        net.train()\n",
    "\n",
    "\n",
    "#print(target_,pred) # used for comparing correct class vs models predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time can vary alot depending on your set parameters, cpu, gpu, whether you're using cuda etc. <br>\n",
    "\n",
    "Now instead of rewriting the above boilerplate pytorch code for training and evaluating the model, ill do cross validation using the skorch library, which basically allows you to abstract away the unnecesarry code, do cross validation and hyper parameter tuning with grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from skorch.dataset import CVSplit\n",
    "from skorch.helper import SliceDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "print(\"Skorch Version: \",skorch.__version__)\n",
    "#del gs\n",
    "#del net\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train.label)\n",
    "y_test = np.array(test.label)\n",
    "params = { # CV testing Parameters, we can add more but keep in mind it takes a very very long time to evaluate all the combinations\n",
    "    # 'module__dropout': [0, 0.5, 0.8], # 3\n",
    "    # 'max_epochs': [3,5,10],\n",
    "    # 'optimizer__momentum': [0,0.9]\n",
    "    'lr': [0.003,0.00003,0.0000003],# * 3\n",
    "    'optimizer__weight_decay' :[0,0.1,0.001], # * 3\n",
    "}\n",
    "# = 27 total config options * number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_array = [\"vgg\",\"google_net\",\"resnet\",\"alexnet\"] # also the order\n",
    "\n",
    "\n",
    "best_params_models = []\n",
    "# the below is used to cross validate and find the best set of specific parameters to use, it takes a very long time to execute\n",
    "first_run = True\n",
    "while(True):\n",
    "    if(len(string_array)>0):\n",
    "        if not first_run:\n",
    "            del skorch_classifier\n",
    "            del net\n",
    "            del gs\n",
    "            del train_sliceable\n",
    "        model_name = string_array.pop(0)\n",
    "        net = get_model(model_name)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        first_run = False\n",
    "    else:\n",
    "        break\n",
    "    print(\"---------------------\")\n",
    "    print(\"---------------------\")\n",
    "    print(\"Now cross validating {}------------------------------------------\".format(model_name))\n",
    "    print(\"---------------------\")\n",
    "    print(\"---------------------\")\n",
    "    skorch_classifier = NeuralNetClassifier(\n",
    "        net,\n",
    "        max_epochs=5,\n",
    "        batch_size=22, #max 22 for me\n",
    "        lr=0.003, # set in params dict\n",
    "        #module__dropout=0.5,\n",
    "        optimizer=torch.optim.SGD,\n",
    "        optimizer__momentum=0.9,\n",
    "        optimizer__weight_decay=0.001,\n",
    "        criterion=nn.CrossEntropyLoss,\n",
    "        device=device,\n",
    "    )\n",
    "    gs = GridSearchCV(skorch_classifier,\n",
    "                      param_grid=params, \n",
    "                      scoring='accuracy', \n",
    "                      verbose=1, # outputs info\n",
    "                      cv=5, # subsets are still stratified (same percentage of labels)\n",
    "                     )\n",
    "    train_sliceable = SliceDataset(train_dataset)\n",
    "    gs.fit(train_sliceable, y_train)\n",
    "    best_params_models.append(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params_models)\n",
    "with open('best_params.json', 'w') as jsonfile: # Save best params for each model\n",
    "    json.dump(best_params_models, jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
