{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that you have pytorch installed, instructions are here: https://pytorch.org/get-started/locally/ , prefferably do it with anaconda if you can, I think that will lead to less problems down the road if we use other libraries.\n",
    "\n",
    "If cuda toolkit isnt available and you have an nvidia gpu try to get that too (it might be contained within anaconda pytorch package): https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html\n",
    "\n",
    "Also note that because the dataset is large I added it to the .gitignore, you should download it from here : https://www.kaggle.com/c/cassava-leaf-disease-classification/data, and extract it into the data/ folder of the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import skorch\n",
    "\n",
    "\n",
    "from torch import FloatTensor, LongTensor, nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets, models\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = True\n",
    "if not torch.cuda.is_available() or not use_cuda:\n",
    "    print(\"if you have an nvidia gpu get the cuda core package\")\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into train and test sets and loading the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setting the path to the directory containing the pics\n",
    "path = './data/train_images'\n",
    "test_path = './data/test_images'\n",
    "\n",
    "labelled_dataset = pd.read_csv(r'./data/train.csv')\n",
    "submission = pd.read_csv(r'./data/sample_submission.csv')\n",
    "\n",
    "with open('./data/label_num_to_disease_map.json') as f:\n",
    "    mapping_dict = json.load(f)\n",
    "print(mapping_dict)\n",
    "\n",
    "#labelled_dataset = labelled_dataset.head(800) # fast debugging, comment when training for real\n",
    "\n",
    "# Parameters 5\n",
    "train, test = train_test_split(labelled_dataset, test_size=0.25, random_state=7, stratify=labelled_dataset.label)\n",
    "\n",
    "should_match_index = 6\n",
    "print(labelled_dataset.values[should_match_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(labelled_dataset.label) # counts the elements' frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Cassava Bacterial Blight (CBB) appears 1087 times<br>\n",
    "Label Cassava Brown Streak Disease (CBSD) appears 2189 times<br>\n",
    "Label Cassava Green Mottle (CGM) appears 2386 times<br>\n",
    "Label Cassava Mosaic Disease (CMD) appears 13158 times<br>\n",
    "Label Healthy appears 2577 times<br>\n",
    "Because the labels arent equally represented the dataset split is stratified so each split has an equal amount of a certain label\n",
    "<br><br>\n",
    "Create custom dataset class for the images, and a transform to be applied to these images as part of preprocessing for learning <br>\n",
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, data, path , transform = None):\n",
    "        super().__init__()\n",
    "        self.data = data.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_name,label = self.data[index]\n",
    "        img_path = os.path.join(self.path, img_name)\n",
    "        image = img.imread(img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# original resolution is 800 x 600\n",
    "# Parameters 5\n",
    "cassava_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((600,600)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(299), #minimum is 299 for inceptionv3 224 for everything else\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    # (the means and standard deviations of each of the 3 image channels)\n",
    "])\n",
    "\n",
    "train_dataset = CassavaDataset(train, path, cassava_transform )\n",
    "test_dataset = CassavaDataset(test, path, cassava_transform)\n",
    "valid_dataset = CassavaDataset(submission, test_path, cassava_transform)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(labelled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0] # how a transformed image tensor looks like, its label is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters 1\n",
    "n_epochs = 10 # on final training this should be high (around 30 for my desktop pc)\n",
    "num_classes = 5 # 5 labels\n",
    "batch_size = 32 # minimum batch size for inception v3 is 2, good general range seems to be 20 to 32\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# using Adam optimizer, the max batch size for me is around 28, after that it uses too much vram (i have 8gb)\n",
    "# using SGD optimizer, i can use up to 32\n",
    "# using different pre processing parameters, i could get bigger batch sizes since the images would be smaller\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True, num_workers=0,pin_memory=True,drop_last=True)\n",
    "valid_dataloader = DataLoader(dataset = valid_dataset, batch_size = batch_size, shuffle=False, num_workers=0,pin_memory=True,drop_last=True)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False, num_workers=0,pin_memory=True,drop_last=True)\n",
    "# pin memory should be enabled if you use cuda cores to speed up transfer between cpu and gpu,\n",
    "# drop last is there if the last batch contains 1 sample for inception v3 (if its not enabled for inception theres an error)\n",
    "# num workers is 0 unless you're using linux or mac os x, because paralelization in windows is broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(index):  \n",
    "    plt.imshow(img.imread('{}/{}'.format(path,labelled_dataset.values[index][0]))) # set the correct resolution here\n",
    "    print('Index: {}'.format(labelled_dataset.values[index][1]))\n",
    "    print('Filename: {}'.format(labelled_dataset.values[index][0]))\n",
    "    \n",
    "show_image(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using resnet 18 pretrained pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__) \n",
    "# Use this number below as the torchvision version or else theres a version conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection below, choices are \"resnet\", \"alexnet\", \"vgg\", \"google\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_string):\n",
    "    if model_string == \"google\":\n",
    "        net = models.inception_v3(pretrained=True) # googlenet is based on inception v1, this is improved\n",
    "        net = net.cuda() if device else net\n",
    "        num_ftrs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        net.fc = net.fc.cuda() if use_cuda else net.fc\n",
    "\n",
    "    if model_string == \"vgg\":\n",
    "        net = models.vgg16(pretrained=True)\n",
    "        net = net.cuda() if device else net\n",
    "        net.fc = nn.Linear(4096, num_classes)\n",
    "        net.fc = net.fc.cuda() if use_cuda else net.fc\n",
    "\n",
    "    if model_string == \"alexnet\":\n",
    "        net = models.alexnet(pretrained=True)\n",
    "        net = net.cuda() if device else net  \n",
    "        net.fc = nn.Linear(4096, num_classes)\n",
    "        net.fc = net.fc.cuda() if use_cuda else net.fc\n",
    "\n",
    "    if model_string == \"resnet\":\n",
    "        #net = torch.hub.load('pytorch/vision:v0.2.2', 'resnet18', pretrained=True)\n",
    "        net = models.resnet18(pretrained=True)\n",
    "        net = net.cuda() if device else net\n",
    "        num_ftrs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        net.fc = net.fc.cuda() if use_cuda else net.fc\n",
    "        \n",
    "    return net\n",
    "    \n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n",
    "\n",
    "# Parameters 2\n",
    "model_index = 0 # set model index to use here\n",
    "run_all_models = True # set if it should run all models, starting with the one set above\n",
    "    \n",
    "string_array = [\"alexnet\",\"vgg\",\"resnet\",\"google\"]\n",
    "model_name = string_array[model_index]\n",
    "net = get_model(model_name)\n",
    "string_array.remove(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do evaluation, (still have to try out parameters specified in paper, find out which are useful) <br>The original base code for the block above this text and block below was found at the following link, but it was modified for our dataset and to work with our 4 different models not just resnet: https://www.pluralsight.com/guides/introduction-to-resnet <br> <br> What I did with the models is called feature extraction, the models were all pretrained on imagenet: <br>\n",
    "\n",
    "In feature extraction, we start with a pretrained model and only update the final layer weights from which we derive predictions. It is called feature extraction because we use the pretrained CNN as a fixed feature-extractor, and only change the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will plot the accuracy of the models below and save them to a file\n",
    "def plot_model_acc():\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.title(\"Train-Validation Accuracy for {}\".format(model_name))\n",
    "    plt.plot(train_acc, label='train')\n",
    "    plt.plot(val_acc, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('accuracy', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('./plots/{}.png'.format(model_name), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_run = True\n",
    "while(True):\n",
    "    if(run_all_models and len(string_array) > 0):\n",
    "        if not first_run:\n",
    "            #Print and save graph\n",
    "            plot_model_acc()\n",
    "            \n",
    "            del criterion # free up vram\n",
    "            del optimizer\n",
    "            del net\n",
    "            torch.cuda.empty_cache()\n",
    "            model_name = string_array.pop(0)\n",
    "            net = get_model(model_name)\n",
    "        else:\n",
    "            first_run = False\n",
    "        \n",
    "        # Parameters 3\n",
    "        criterion = nn.CrossEntropyLoss() # used this since we have 5 mutually exclusive classes\n",
    "        #either one of the optimizers work\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        #optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        \n",
    "    else:\n",
    "        plot_model_acc()\n",
    "        break\n",
    "    print(\"Using model: {}\".format(model_name))\n",
    "    print_every = int(len(train_dataloader)*0.1) # print upon completion of every 10% of the dataset\n",
    "    valid_loss_min = np.Inf\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    total_step = len(train_dataloader)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total=0\n",
    "        print(f'Epoch {epoch}\\n')\n",
    "        for batch_idx, (data_, target_) in enumerate(train_dataloader):\n",
    "            data_, target_ = data_.to(device), target_.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(data_)\n",
    "            if model_name == \"google\": # for inception v3 (the google model we use): \n",
    "                # net(data_) returns logits and aux logits in a touple, we just use logits\n",
    "                outputs = outputs[0]\n",
    "            loss = criterion(outputs, target_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _,pred = torch.max(outputs, dim=1)\n",
    "\n",
    "            #set_trace() # Debugger entrypoint for inspecting predictions\n",
    "\n",
    "            correct += torch.sum(pred==target_).item()\n",
    "            total += target_.size(0)\n",
    "            if (batch_idx) % print_every == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "        train_acc.append(100 * correct / total)\n",
    "        train_loss.append(running_loss/total_step)\n",
    "        print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "        batch_loss = 0\n",
    "        total_t=0\n",
    "        correct_t=0\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for data_t, target_t in (test_dataloader):\n",
    "                data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "                outputs_t = net(data_t)\n",
    "                loss_t = criterion(outputs_t, target_t)\n",
    "                batch_loss += loss_t.item()\n",
    "                _,pred_t = torch.max(outputs_t, dim=1)\n",
    "                correct_t += torch.sum(pred_t==target_t).item()\n",
    "                total_t += target_t.size(0)\n",
    "            val_acc.append(100 * correct_t/total_t)\n",
    "            val_loss.append(batch_loss/len(test_dataloader))\n",
    "            network_learned = batch_loss < valid_loss_min\n",
    "            print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "\n",
    "            if network_learned:\n",
    "                valid_loss_min = batch_loss\n",
    "                torch.save(net.state_dict(), './data/{}_best_model.pt'.format(model_name))\n",
    "                print('Improvement-Detected, save-model')\n",
    "        net.train()\n",
    "        \n",
    "#print(target_,pred) # used for comparing correct class vs models predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time can vary alot depending on your set parameters, cpu, gpu, whether you're using cuda etc. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
